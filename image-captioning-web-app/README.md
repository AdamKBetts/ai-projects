# Project 4: Interactive Image Captioning Web App

This project transforms a local AI script into a user-friendly web application using the **Flask** framework. It showcases the crucial skill of **MLOps (Machine Learning Operations)**, specifically the deployment of a machine learning model to be accessible via a simple web interface. The application allows users to upload an image and receive a descriptive caption generated by a pre-trained Vision-Language Model (VLM).

---

### Features ‚ú®

- **Web Interface:** A clean, simple web page for user interaction.
- **API Endpoint:** Handles image uploads and returns a generated caption in JSON format.
- **Backend Integration:** The AI model runs on the server, ensuring efficient processing.
- **Containerization-Ready:** The project structure is ready to be containerized with Docker for easy deployment to cloud platforms.

---

### Core Components üß©

- **Flask:** A lightweight Python web framework used to build the web server and handle HTTP requests.
- **Hugging Face Transformers:** Provides the core AI model (`BLIP`) for image captioning.
- **Pillow:** Used for reading and processing image files on the server.

---

### Installation üõ†Ô∏è

1.  **Navigate to the project directory:**

    ```bash
    cd image-captioning-web-app
    ```

2.  **Install the required libraries:**
    ```bash
    pip install Flask transformers Pillow
    ```

---

### Usage ‚ñ∂Ô∏è

1.  **Run the Flask server:**

    ```bash
    python app.py
    ```

    The first time you run this, it will download the BLIP model (around 400MB).

2.  **Access the web app:**
    Open your web browser and navigate to the local address shown in your terminal, typically **`http://127.0.0.1:5000/`**.

3.  **Upload and Caption:**
    Use the simple web interface to upload an image. The caption will appear on the page after a few moments.

---
